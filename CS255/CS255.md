# CS255

## Intro to AI

Required reading: AIFCA Sec 2.1-2.2

#### Definition

> **Artificial Intelligence** is the synthesis and analysis of agents acting intelligently.

An **intelligent** agent:
- acts appropriately for its goals
- is flexible to changing goals
- learns from experience
- makes appropriate choices within its perceptual and compuatational limitations

#### Goals of AI

The **scientific goal** is to understand what makes intelligent behaviour possible in natural and artificial systems.

The **engineering goal** is to design useful artefacts.

## Rational Agents

#### Definition
> An **agent** is an entity that percieves and acts.

An agent is designed to perform specific tasks with a level of autonomy. It can be viewed as a function from **percept histories** to **actions**.

$$f: P \to A$$

### Inputs to an Agent

We give an agent several inputs.

- **Abilities** (the set of possible actions)
- **Goals** (what we want the agent to achieve)
- **Prior Knowledge** (the set of initial knowledge)
- **History of Stimuli** (current stimuli and the past experiences)

Rational agents act *rationally*. A **rational action** maximises the expected value of the outcome (represented numerically) when given the history of perceptions.

> Rational actions are not **omniscient** because of unexpected events which happen in reality.

>Rational actions are not **clairvoyant**, nor is it necessarily **successful**.

### Dimensions of Complexity
These describe the design space when training an agent.

#### Modularity
> Is the structure of the agent subdivided into modules, each designed for learning from different environments?

- A **flat** representation is simply a singularly trained agent.
- A **modular** representation is split into different modules.
- A **heirarchical** representation is split into a hierarchy of groups of modules.

#### Planning Horizon
> How far in the future does the agent look?
- Static/Finite/Indefinite/infinite

#### Representation
> How is a computational gain represented?

#### Computational Limits
> What are they? Is perfect rationality possible or is it bounded?

#### Learning from experience
> Is knowledge given or taught via its perceptions?

#### Sensing Uncertainty
> Is the state of the world fully observable?

#### Effect Uncertainty
> Can the agent reliably predict the resulting state given some set of stimuli and actions? That is, is our agent deterministic?

#### Preferences
> Is there some definite goal or is it a mix of trade-offs?

#### Number of Agents
> Is only caring about one agent sufficient?

#### Interaction
> Does the agent reason an outcome before an action (offline) or during it (online)?